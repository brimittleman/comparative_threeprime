---
title: "Quantify reads per Peaks"
author: "Briana Mittleman"
date: "8/24/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##Feature count  
In this analysis I will run feature counts on the human and chimp,total and nuclear threeprime seq libraries agaisnt the orthologous peaks I called with liftover. 

First I will need to convert the bed files to saf files. This File is GeneID, Chr, Start, End, Strand. In my case it is peak ID.  

```{bash, eval=F}

#human
from misc_helper import *

fout = file("/project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/humanOrthoPeaks.sort.SAF",'w')
fout.write("GeneID\tChr\tStart\tEnd\tStrand\n")
for ln in open("/project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/humanOrthoPeaks.sort.bed"):
    chrom, start, end, name = ln.split()
    start=int(start)
    end=int(end)
    fout.write("%s\t%s\t%d\t%d\t.\n"%(name, chrom, start, end))

fout.close()


#chimp
from misc_helper import *

fout = file("/project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/chimpOrthoPeaks.sort.SAF",'w')
fout.write("GeneID\tChr\tStart\tEnd\tStrand\n")
for ln in open("/project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/chimpOrthoPeaks.sort.bed"):
    chrom, start, end, name = ln.split()
    start=int(start)
    end=int(end)
    fout.write("%s\t%s\t%d\t%d\t.\n"%(name, chrom, start, end))

fout.close()



```

The resulting files are:  

* /project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/chimpOrthoPeaks.sort.saf  

* /project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/humanOrthoPeaks.sort.saf


```{bash, eval=F}
#!/bin/bash

#SBATCH --job-name=fc_orthopeaks
#SBATCH --account=pi-yangili1
#SBATCH --time=24:00:00
#SBATCH --output=fc_orthopeaks.out
#SBATCH --error=fc_orthopeaks.err
#SBATCH --partition=broadwl
#SBATCH --mem=12G
#SBATCH --mail-type=END


module load Anaconda3
source activate comp_threeprime_env

# outdir: /project2/gilad/briana/comparitive_threeprime/data/Peak_quant

#-s 0 is unstranded 

featureCounts -a /project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/humanOrthoPeaks.sort.SAF -F SAF -o /project2/gilad/briana/comparitive_threeprime/data/Peak_quant/HumanTotal_Orthopeak.quant /project2/gilad/briana/comparitive_threeprime/human/data/sort/*T-sort.bam -s 0

featureCounts -a /project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/humanOrthoPeaks.sort.SAF -F SAF -o /project2/gilad/briana/comparitive_threeprime/data/Peak_quant/HumanNuclear_Orthopeak.quant /project2/gilad/briana/comparitive_threeprime/human/data/sort/*N-sort.bam -s 0


featureCounts -a /project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/chimpOrthoPeaks.sort.SAF -F SAF -o /project2/gilad/briana/comparitive_threeprime/data/Peak_quant/ChimpTotal_Orthopeak.quant /project2/gilad/briana/comparitive_threeprime/chimp/data/sort/*T-sort.bam -s 0

featureCounts -a /project2/gilad/briana/comparitive_threeprime/data/ortho_peaks/chimpOrthoPeaks.sort.SAF -F SAF -o /project2/gilad/briana/comparitive_threeprime/data/Peak_quant/ChimpNuclear_Orthopeak.quant /project2/gilad/briana/comparitive_threeprime/chimp/data/sort/*N-sort.bam -s 0

```

##Visualize raw counts  

I need the matching peaks from human and chimps from the liftover pipeline data.  

```{r}
library(workflowr)
library(tidyverse)
library(reshape2)
library(cowplot)
```


```{r}
PeakNames=read.table(file = "../data/liftover/HumanChimpPeaknames.txt", header=T, stringsAsFactors = F)
```

Chimps:  

* 18358  
* 3622  
* 3659  
* 4973  
* pt30  
* pt91  

Humans:  

* 18498  
* 18499 
* 18502  
* 18504  
* 18510 
* 18523   

```{r}

namesHN= c("human","Chr", "Start", "End", "Strand", "Length", "N18498", "N18499", "N18502", "N18504", "N18510", "N18523")
humanNuc=read.table("../data/orthoPeak_quant/HumanNuclear_Orthopeak.quant", header = T, stringsAsFactors = F, col.names = namesHN)

namesHT= c("human","Chr", "Start", "End", "Strand", "Length", "T18498", "T18499", "T18502", "T18504", "T18510", "T18523")
humanTot=read.table("../data/orthoPeak_quant/HumanTotal_Orthopeak.quant", header=T, stringsAsFactors = F, col.names = namesHT)


namesCN= c("chimp","Chr", "Start", "End", "Strand", "Length", "N18358", "N3622", "N3659", "N4973", "Npt30", "Npt91")

chimpNuc=read.table("../data/orthoPeak_quant/ChimpNuclear_Orthopeak.quant", header = T,stringsAsFactors = F, col.names = namesCN)

namesCT= c("chimp","Chr", "Start", "End", "Strand", "Length", "T18358", "T3622", "T3659", "T4973", "Tpt30", "Tpt91")
chimpTot=read.table("../data/orthoPeak_quant/ChimpTotal_Orthopeak.quant", header=T, stringsAsFactors = F, col.names = namesCT)

```


I need to add the human names to the chimp file and chimp names to the human files.  

```{r}
humanNuc_ed= humanNuc %>% inner_join(PeakNames, by="human") %>% mutate(ID=paste(human,chimp, sep=":")) %>% select("ID",  "N18498", "N18499", "N18502", "N18504", "N18510", "N18523")

humanTot_ed= humanTot %>% inner_join(PeakNames, by="human") %>%mutate(ID=paste(human,chimp, sep=":")) %>% select("ID",  "T18498", "T18499", "T18502", "T18504", "T18510", "T18523")

chimpNuc_ed=chimpNuc %>% inner_join(PeakNames, by="chimp") %>% mutate(ID=paste(human,chimp, sep=":")) %>% select("ID", "N18358", "N3622", "N3659", "N4973", "Npt30", "Npt91")

chimpTot_ed= chimpTot %>% inner_join(PeakNames, by="chimp") %>% mutate(ID=paste(human,chimp, sep=":")) %>% select("ID", "T18358", "T3622", "T3659", "T4973", "Tpt30", "Tpt91")

``` 


Now I need to join all of these together by the peaks.  

```{r}
allPeakQuant= humanNuc_ed %>% left_join(humanTot_ed, by="ID") %>% left_join(chimpNuc_ed, by="ID") %>% left_join(chimpTot_ed, by="ID") %>% column_to_rownames(var="ID")
allPeakQuant_matrix=as.matrix(allPeakQuant) 
```



Run PCA:  



```{r}

humans=c("N18498", "N18499", "N18502", "N18504", "N18510", "N18523", "T18498", "T18499", "T18502", "T18504", "T18510", "T18523")
pc=prcomp(allPeakQuant_matrix)
rotation=data.frame(pc$rotation) %>% rownames_to_column(var="Sample") %>% mutate(Fraction=ifelse(grepl("N", Sample), "Nuclear", "Total")) %>% mutate(Species= ifelse(Sample %in% humans, "Human", "Chimp"))



```


Plot this:  

```{r}
prenormPCA=ggplot(rotation, aes(x=PC1, y=PC2, col=Species, shape=Fraction)) + geom_point() + labs(title="Prenormalization PCA")

prenormPCA34=ggplot(rotation, aes(x=PC3, y=PC4, col=Species, shape=Fraction)) + geom_point() + labs(title="Prenormalization PCA")

prenormPCA56=ggplot(rotation, aes(x=PC5, y=PC6, col=Species, shape=Fraction)) + geom_point() + labs(title="Prenormalization PCA")

prenormPCA78=ggplot(rotation, aes(x=PC7, y=PC8, col=Species, shape=Fraction)) + geom_point() + labs(title="Prenormalization PCA")


```





```{r}
plot_grid(prenormPCA,prenormPCA34, prenormPCA56, prenormPCA78)
```
##Normalize counts  

To normalize this i will need to understand the distributions. I am not sure if this data will be normal.  

```{r}
library(edgeR)
```

```{r}
allPeakQuant_matrix_cpm=cpm(allPeakQuant_matrix, log=T)

plotDensities(allPeakQuant_matrix_cpm, legend = "bottomright", main="Pre-filtering")
abline(v = 0, lty = 3)
```
 
```{r}

par(mfrow=c(2,1))
boxplot(log10(allPeakQuant + 1), main="Log Raw Counts + 1")
boxplot(allPeakQuant_matrix_cpm, main="Log CPM Counts")


```



I should think about other normalization types. I am going to look at other papers to see what they do. For example, Derti et al. 2012.  

"All samples were normalized to equal numbers of aligned sequencing reads by random selection"  

Things to think about:

* peak size diff in human/chimp  

* divide by lib size or mapped reads or reads mapping to peaks  


From Wang et al. 2018  

* reads per million for all samples (RPM)  

* percent of samples with expression (PSE)  

* mean RPM and PSE of each isoform normalzied by summed RPM and max PSE of all isoforms of the corresponding gene (relative abundance and normalzied PSE)

* PAS expressed in sample if >2 reads per sample 

* diversity - Shannon Index $D=\sum^{S}_{i=1}p_{i}lnp_{i}$ where $p_{i}$ is the relative usage of the ith PAS for a given gene with S number of PAS  

I will compute the PRM for the matrix using the library read counts.  

```{r}
read_stats=read.csv("../data/map.stats.csv", header = T) %>% mutate(library=paste(substr(Fraction,1,1), Line, sep="")) %>% select(library, Reads)
```

I want to divide the values in the column corresponding to a specific library by the value in the Reads columns in the map_stats. I will use for loops for now (should use apply)  
```{r}
allPeakQuant_matrix_rpm=as.data.frame(matrix("NA", nrow = nrow(allPeakQuant_matrix), ncol=ncol(allPeakQuant_matrix)))
colnames(allPeakQuant_matrix_rpm)=colnames(allPeakQuant_matrix)
rownames(allPeakQuant_matrix_rpm)=rownames(allPeakQuant_matrix)

library_order=order(read_stats$library)

allPeakQuant_matrix_rpm=allPeakQuant_matrix_rpm[,order(library_order)]
allPeakQuant_matrix=allPeakQuant_matrix[,order(library_order)]
read_stats_T=read_stats%>% t  


#filter for more than 2 reads
allPeakQuant_matrix_filt=ifelse(allPeakQuant_matrix<=2,0,allPeakQuant_matrix)



#make RPM
for (i in seq(1:ncol(allPeakQuant_matrix))) {
  x=as.integer(read_stats_T[2,i])/1000000
  allPeakQuant_matrix_rpm[,i]=as.vector(allPeakQuant_matrix_filt[,i])/x
}


```

```{r}

par(mfrow=c(2,1))
boxplot(log10(allPeakQuant + 1), main="Log Raw Counts + 1")
boxplot(log10(allPeakQuant_matrix_rpm + 1), main="log 10 RPM Counts + 1")


```
```{r}
plotDensities(log10(allPeakQuant_matrix_rpm+1), legend = "bottomright", main="RPM")
abline(v = 0, lty = 3)
```
Normalize by the sample RPM average for each sample: 
```{r}
RPM_mean=apply(allPeakQuant_matrix_rpm, 2,function(x)mean(x))


allPeakQuant_matrix_rpm_Norm=allPeakQuant_matrix_rpm



for (i in seq(1:ncol(allPeakQuant_matrix_rpm_Norm))) {
  allPeakQuant_matrix_rpm_Norm[,i]=as.vector(allPeakQuant_matrix_rpm[,i])/RPM_mean[i]
}

```


```{r}
par(mfrow=c(2,1))
boxplot(log10(allPeakQuant + 1), main="Log Raw Counts + 1")
boxplot(log10(allPeakQuant_matrix_rpm_Norm + 1), main="Normalized log 10 RPM Counts + 1")

```
```{r}

plotDensities(log10(allPeakQuant_matrix_rpm_Norm+1), legend = "bottomright", main="log10 normalized RPM + 1")
abline(v = 0, lty = 3)
```

*I now have normalized values that are filtered for peaks that had >2 reads.*


##Differential analysis: 

I need to make a design matrix accounting for the two groups each sample can be in. It can be human chimp and total/nuclear. I could also run the analysis seperatly on total and nuclear and just look for differences between hunman and chimp first

Expression matrix:  

```{r}
x=as.matrix(allPeakQuant_matrix_rpm_Norm)
```


Create the feature data- this has 1 row per pas.  

```{r}
f=as.data.frame(rownames(allPeakQuant_matrix_rpm_Norm)) 
colnames(f)= c("ID") 
f = f %>% separate(ID, into=c("Human", "Chimp"), remove = F, sep=":") %>% mutate(name=ID) 
f = f %>% column_to_rownames("name")
```


Create phenotype data frame:  

```{r}
p=read.csv("../data/comp.pheno.data.csv",header = T)
p= p %>% column_to_rownames(var="Sample")
```


Try a boxplot with these: 
```{r}
boxplot(x[1,]~p[,"Species"], main=f[1,"ID"]) 
boxplot(x[1,]~p[,"Fraction"], main=f[1,"ID"]) 


```
Create expression set object:  
```{r}
library(Biobase)
eset=ExpressionSet(assayData = x,
                   phenoData = AnnotatedDataFrame(p),
                   featureData = AnnotatedDataFrame(f))
```



Limma package for DE. Problem, emprical bayes probably relies on independent genes. Some of these peaks go to the same gene, therefore are not indep. I get around this when i use the leafcutter phenotype that is usage of the peak compared to others in the gene. (ill do this later)

First I will do human/chimp as explanatory. 

```{r}
library(limma)
design=model.matrix(~ Species , data=pData(eset))
fit=lmFit(eset,design)
fit=eBayes(fit)
results=decideTests(fit[,"SpeciesHuman"])
summary(results)

```

Second I can do this against fraction:  

```{r}
design2=model.matrix(~ Fraction , data=pData(eset))
fit2=lmFit(eset,design2)
fit2=eBayes(fit2)
results2=decideTests(fit2[,"FractionTotal"])
summary(results2)
```
Try with both
```{r}

design3=model.matrix(~ Fraction + Species , data=pData(eset))
fit3=lmFit(eset,design3)
fit3=eBayes(fit3)
results3a=decideTests(fit3[,"FractionTotal"])
results3b=decideTests(fit3[,"SpeciesHuman"])
summary(results3a)
summary(results3b)
```

It looks like the most peaks are down regulated in total in comparison to nuclear. This makes sense because we expect more peaks to be used in the nuclear fraction.  

